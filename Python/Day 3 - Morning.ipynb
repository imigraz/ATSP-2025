{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d3f524-8f73-4813-937b-b3e0300ecbdf",
   "metadata": {},
   "source": [
    "# Day 3 - Morning - Assignment\n",
    "\n",
    "In this session, we will discuss your assignments. \n",
    "\n",
    "We will look at each assignment in detail, and you will get the chance to start your assignments and ask questions, and we can work through the assignments together in this morning session. \n",
    "\n",
    "You have the choice of one of two different assignments.\n",
    "\n",
    "Here are your choices, choose **one** of the following: \n",
    "\n",
    "1. Medical image classification\n",
    "2. Streamlit web application\n",
    "\n",
    "## Deadline\n",
    "\n",
    "**Deadline is the 25th of March!!**\n",
    "\n",
    "**Note**: Send your assignments in a single Zip file, as the Med Uni Graz spam filter will block files ending in `.py` for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c428f-e3f1-4bc3-afcd-202f8c30cedb",
   "metadata": {},
   "source": [
    "## 1. Medical Image Classificaiton\n",
    "\n",
    "In this task, you are expected to classify histopathology images. \n",
    "\n",
    "For this, we will use MedMNIST, specifically **PathMNIST**.\n",
    "\n",
    "You can find informaton about MedMNIST and specifically PathMNIST here: <https://medmnist.com>\n",
    "\n",
    "Here is the information provided by the package:\n",
    "\n",
    "> The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We split the 100,000 images into training and validation set with a ratio of 9:1.\n",
    "\n",
    "PathMNIST consists of more than 100,000 images.\n",
    "\n",
    "It is a 9-class classification problem, where you should classify the type of tissue in to the following classes:\n",
    "\n",
    "- '0': 'adipose' \n",
    "- '1': 'background'\n",
    "- '2': 'debris'\n",
    "- '3': 'lymphocytes'\n",
    "- '4': 'mucus'\n",
    "- '5': 'smooth muscle'\n",
    "- '6': 'normal colon mucosa'\n",
    "- '7': 'cancer-associated stroma'\n",
    "- '8': 'colorectal adenocarcinoma epithelium'\n",
    "\n",
    "Options:\n",
    "\n",
    "1. Use large images (as large as possible, but at least 128)\n",
    "2. Resampling to re-balance the dataset during training\n",
    "3. Use a Pre-trained Network (PyTorch Hub), for example ResNet. ResNet is available in difference depths, with ResNet18 being the smallest. The deeper the network, the more memory you will need and the longer it will require to train, but potentially the deeper the network the better the performance.\n",
    "4. Augmentation (Use the PyTorch `transforms.Compose` code from the seminar notebooks)\n",
    "5. Change from 9 class to 2 class (malignant/benign): use this as a last resort. In this case, you reduce the problem down to a binary classification problem, which is much easier task than the 9-class classification problem.\n",
    "\n",
    "The best and easiest solution might be to train a network using the full sized images. Here are the available image sizes for PathMNIST:\n",
    "\n",
    "```python\n",
    "from medmnist import PathMNIST\n",
    "\n",
    "PathMNIST.available_sizes\n",
    "```\n",
    "\n",
    "returns the following: `[28, 64, 128, 224]`.\n",
    "\n",
    "The size 224x224 is common among pre-trained networks as this was a size often used by competitions over the years.\n",
    "\n",
    "For example, ResNet18 has been pre-trained on ImageNet, and these are 224x224 images. Hence, using PyTorch Hub to get a pretrained ResNet18 is a quick way to get going:\n",
    "\n",
    "```python\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "```\n",
    "\n",
    "However, it is likely that an even larger ResNet will be needed to get good results. You can see the different sized ResNet models here: <https://pytorch.org/hub/pytorch_vision_resnet/> \n",
    "\n",
    "However, ImageNet is a 1,000 class classification dataset, and therefore ResNet18 will have 1,000 output neurons, while PathMNIST has 9 classes. You will need to adjust the output layer to have 9 output neurons instead of 1,000.\n",
    "\n",
    "This can be done using the following syntax:\n",
    "\n",
    "```python\n",
    "num_classes = 9\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "```\n",
    "\n",
    "### Colab\n",
    "\n",
    "If you want to work on the larger images, you might need to use a GPU, especially if you decide to use some of the very deep ResNet models. You can get a free GPU from Google Colab:\n",
    "\n",
    "<https://colab.research.google.com/>\n",
    "\n",
    "Change the runtime to GPU: Click Runtime -> Change runtime type and select T4 GPU.\n",
    "\n",
    "**Google Colab users**: If you encounter issues with PyTorch complaining about a missing GPU device with the example code provided in the 'Day 2 - Morning.ipynb' notebook, you can run the following after you have imported Torch:\n",
    "\n",
    "```python\n",
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "\n",
    "### ResNet Sizes\n",
    "\n",
    "ResNet is available in several depths:\n",
    "\n",
    "```python\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = models.resnet34(pretrained=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = models.resnet101(pretrained=True)\n",
    "model = models.resnet152(pretrained=True)\n",
    "```\n",
    "\n",
    "The larger the network, the longer it will require to train and the memory it will require. However, larger networks may improve performance.\n",
    "\n",
    "### Fine Tuning\n",
    "\n",
    "If you wish to **fine-tune** a pre-trained network, the following code can be used:\n",
    "\n",
    "```python\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "```\n",
    "\n",
    "Fine tuning 'freezes' most of the pre-trained network's layers so that they are not updating during fine-tuning. Therefore fine-tuning is the act of training a pre-trained network, where you only update the final layer or final several layers during training. The early layers of the network are frozen in that case.\n",
    "\n",
    "The code above should be placed before you adjust the final output layer to 9 neurons for the 9 output classes of PathMNIST.\n",
    "\n",
    "Fine tuning normally is quite a bit faster than training the entire network, as only the final layer's weights are updated during training.\n",
    "\n",
    "### Submission\n",
    "Send a Jupyter notebook with the accuracy, classification report, confusion matrix, etc (please send a `.zip` file as some code files are blocked by the spam filter). Please also provide a short summary of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050973c-9dd2-40ca-88bf-2e3d1081c8d0",
   "metadata": {},
   "source": [
    "## 2. Streamlit Web Application\n",
    "\n",
    "For Streamlist installation instructions see the end of this section.\n",
    "\n",
    "### Overview\n",
    "\n",
    "For this assignment, you must create a Streamlit application. The web app should let a user enter some details about the house, and it should predict the house price. \n",
    "\n",
    "A model is provided here [house_price_model.pickle](./house_price_model.pickle) - right click the file in the file browser to the left in Jupyter and click Download.\n",
    "\n",
    "See the [House-Price-Model.ipynb](./House-Price-Model.ipynb) notebook for details on how the data and the model was generated.\n",
    "\n",
    "### Training Your Own Model\n",
    "\n",
    "**If you wish to train your own model**:\n",
    "\n",
    "- You must train a model on some data about house prices.\n",
    "- Here is a house price dataset: <https://www.kaggle.com/datasets/yasserh/housing-prices-dataset>\n",
    "- Use only 3 or 4 of the features, e.g. area, number of bedrooms, and number of bathrooms. \n",
    "\n",
    "### Web Application Interface\n",
    "\n",
    "The web app should contain 3 fields (area, number of bedrooms, number of bathrooms), and send the values to the model if all 3 fields are completed.\n",
    "\n",
    "Use something like \n",
    "\n",
    "```python\n",
    "text1 = st.text_input(label=\"Area Square Meters\")\n",
    "```\n",
    "\n",
    "to create text fields.\n",
    "\n",
    "You can control for user input in the Streamlit application. For example, you can check if all the fields (area, etc.) are filled in **and** check if number of bedrooms or number of bathrooms are all greater than 1 before sending the data to the model.\n",
    "\n",
    "### Loading a Model\n",
    "\n",
    "You can load a *pickled* model using:\n",
    "\n",
    "```python\n",
    "import pickle \n",
    "\n",
    "with open('house_price_model.pickle', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "area = 200\n",
    "bedrooms = 3\n",
    "bathrooms = 2\n",
    "\n",
    "# Because we trained with Pandas DataFrames, it is best to pass a DataFrame to the model\n",
    "new_house = pd.DataFrame({\n",
    "    'area_sqm': [area],\n",
    "    'bedrooms': [bedrooms],\n",
    "    'bathrooms': [bathrooms]\n",
    "})\n",
    "\n",
    "predicted_price = loaded_model.predict(new_house)\n",
    "```\n",
    "\n",
    "This will return the prediction of the house price given 200 sqaure metres for area, 3 bedrooms, and 2 bathrooms.\n",
    "\n",
    "### Installing Streamlit\n",
    "\n",
    "Streamlit needs to be run locally for you to do this assignment. \n",
    "\n",
    "1. First create a virtual environment in your project's directory. From the terminal/command line run:\n",
    "\n",
    "```bash\n",
    "$ python -m venv atsp\n",
    "```\n",
    "\n",
    "This will create a virtual environment called `atsp` in the current directory. \n",
    "\n",
    "2. Activate the virtual enviroment:\n",
    "\n",
    "```bash\n",
    "$ source atsp/bin/activate\n",
    "```\n",
    "\n",
    "3. Install Streamlit, Torch, and Watchdog:\n",
    "\n",
    "```bash\n",
    "$ pip install streamlit torch torchvision watchdog\n",
    "```\n",
    "\n",
    "This will install the pacakges to your virtual environment. \n",
    "\n",
    "Note, you need to reactivate the virtual environment every time you work on the project. Do this with the `source atsp/bin/activate` command. \n",
    "\n",
    "To start a Streamlit application, just run `streamlit run` followed by the Python filename from the command line, such as:\n",
    "\n",
    "```bash\n",
    "$ streamlit run my_app.py\n",
    "```\n",
    "\n",
    "The virtual environment must be active for this to work! \n",
    "\n",
    "\n",
    "### Submission\n",
    "\n",
    "Python file with the Streamlit application code (please send a `.zip` file as `.py` files are blocked by the spam filter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
